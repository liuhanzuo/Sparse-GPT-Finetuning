"""
æé™å‹ç¼©å®éªŒï¼š90%+ å‚æ•°å‰ªæ
è­¦å‘Šï¼šè¿™æ˜¯ä¸€ä¸ªé«˜é£é™©å®éªŒï¼Œæ¨¡å‹æ€§èƒ½ä¼šå¤§å¹…ä¸‹é™

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç¡®ä¿å·²ç»è¿è¡Œè¿‡ run_fsdp_finetune.py éªŒè¯ç¯å¢ƒ
2. (å¯é€‰) å…ˆç”¨ SparseGPT.ipynb ç”Ÿæˆ pruned_models/opt-125m-0.1.pt
3. è¿è¡Œæœ¬è„šæœ¬è¿›è¡Œæé™å‹ç¼©å¾®è°ƒ

æ³¨æ„ï¼š
- å¦‚æœå·²æœ‰ 0.1 ç¨€ç–åº¦çš„å‰ªææ¨¡å‹ï¼Œå°†åŠ è½½å®ƒ
- å¦‚æœæ²¡æœ‰ï¼Œå°†ç›´æ¥åœ¨æœªå‰ªææ¨¡å‹ä¸Šè®­ç»ƒï¼ˆæ•ˆæœä¼šå·®å¾ˆå¤šï¼‰
- æ¨èå…ˆç”¨ SparseGPT.ipynb ç”Ÿæˆå‰ªææ¨¡å‹
"""

from fsdp_finetune import fsdp_finetune
import os

def extreme_compression_experiment(target_sparsity=0.1, model_name="opt-125m", batch_size=1):
    """
    æé™å‹ç¼©å®éªŒ
    
    Args:
        target_sparsity: ç›®æ ‡ç¨€ç–åº¦ï¼Œ0.1 = 90% å‹ç¼©ï¼Œ0.05 = 95% å‹ç¼©
        model_name: æ¨¡å‹åç§°
        batch_size: æ‰¹å¤§å°ï¼Œå¢åŠ å¯ä»¥åŠ é€Ÿè®­ç»ƒä½†éœ€è¦æ›´å¤šæ˜¾å­˜
    """
    
    compression_rate = (1 - target_sparsity) * 100
    remaining_params = target_sparsity * 100
    
    print("=" * 70)
    print("ğŸš€ æé™å‹ç¼©å®éªŒï¼šSparseGPT é«˜ç¨€ç–åº¦å¾®è°ƒ")
    print("=" * 70)
    print(f"æ¨¡å‹: facebook/{model_name}")
    print(f"ç›®æ ‡ç¨€ç–åº¦: {target_sparsity}")
    print(f"ä¿ç•™å‚æ•°: {remaining_params:.1f}%")
    print(f"å‹ç¼©ç‡: {compression_rate:.1f}%")
    print("=" * 70)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å‰ªææ¨¡å‹
    pruned_model_path = f'pruned_models/{model_name}-{target_sparsity}.pt'
    has_pruned_model = os.path.exists(pruned_model_path)
    
    if has_pruned_model:
        print(f"âœ… æ‰¾åˆ°å‰ªææ¨¡å‹: {pruned_model_path}")
        print("   å°†åŠ è½½å¹¶å¾®è°ƒå‰ªæåçš„æ¨¡å‹")
    else:
        print(f"âš ï¸  æœªæ‰¾åˆ°å‰ªææ¨¡å‹: {pruned_model_path}")
        print("   å°†ä½¿ç”¨æœªå‰ªæçš„æ¨¡å‹è®­ç»ƒï¼ˆæ•ˆæœä¼šå·®å¾ˆå¤šï¼‰")
        print()
        print("ğŸ”§ å»ºè®®æ­¥éª¤ï¼š")
        print("   1. æ‰“å¼€ SparseGPT.ipynb")
        print(f"   2. è®¾ç½® SPARSENESS_LIST = [{target_sparsity}]")
        print("   3. è¿è¡Œ notebook ç”Ÿæˆå‰ªææ¨¡å‹")
        print("   4. å†è¿è¡Œæœ¬è„šæœ¬è¿›è¡Œå¾®è°ƒ")
        print()
        response = input("æ˜¯å¦ç»§ç»­ä½¿ç”¨æœªå‰ªææ¨¡å‹? (y/N): ")
        if response.lower() != 'y':
            print("å®éªŒå–æ¶ˆ")
            return
    
    print("=" * 70)
    
    # æ ¹æ® batch_size è‡ªåŠ¨è°ƒæ•´ max_step
    # ä¿æŒæ€»æ•°æ®é‡çº¦ 10,000 ä¸ªæ ·æœ¬
    base_samples = 10000
    max_step = base_samples // batch_size
    
    # æ ¹æ® batch_size è°ƒæ•´å­¦ä¹ ç‡
    # ç»éªŒæ³•åˆ™ï¼šbatch_size ç¿»å€ï¼Œå­¦ä¹ ç‡ä¹Ÿå¯ä»¥é€‚å½“å¢åŠ ï¼ˆä½†ä¸è¦çº¿æ€§å¢åŠ ï¼‰
    base_lr = 5e-6
    lr = base_lr * (batch_size ** 0.5)  # ä½¿ç”¨å¹³æ–¹æ ¹ç¼©æ”¾
    
    # é…ç½®å‚æ•°
    config = {
        "lr": lr,
        "num_epochs": 10,
        "seed": 42,
        "batch_size": batch_size,
        "model_name": model_name,
        "sparsity": target_sparsity,
        "train_steps": max_step,
        "max_step": max_step,
        "save_model": True,
        "resume":True,
        "use_lora_per_layer": True,
        "lora_epochs": 5,
        "lora_r": 16,
        "lora_alpha": 32,
        "lora_dropout": 0.1,
        "unfreeze_base": True
    }
    
    print("ğŸ“‹ è®­ç»ƒé…ç½®:")
    print(f"   æ‰¹å¤§å°: {config['batch_size']}")
    print(f"   å­¦ä¹ ç‡: {config['lr']:.2e} (è‡ªåŠ¨è°ƒæ•´)")
    print(f"   è®­ç»ƒè½®æ¬¡: {config['num_epochs']}")
    print(f"   æ¯è½®æœ€å¤§æ­¥æ•°: {config['max_step']}")
    print(f"   æ€»æ ·æœ¬æ•°/è½®: ~{batch_size * max_step}")
    print(f"   é¢„æœŸä¼˜åŒ–å™¨æ›´æ–°/è½®: ~{max_step}")
    print("=" * 70)
    print("âš ï¸  è­¦å‘Šï¼š")
    print(f"   - {compression_rate:.0f}% å‹ç¼©ç‡ä¼šå¯¼è‡´æ˜¾è‘—æ€§èƒ½ä¸‹é™")
    if batch_size > 1:
        print(f"   - Batch size={batch_size} éœ€è¦ ~{batch_size}GB æ˜¾å­˜")
    print("   - è®­ç»ƒæ—¶é—´è¾ƒé•¿ï¼Œé¢„è®¡ 30-60 åˆ†é’Ÿ")
    print("   - å»ºè®®ä» 0.2 ç¨€ç–åº¦å¼€å§‹é€æ­¥å°è¯•")
    print("=" * 70)
    
    input("æŒ‰ Enter å¼€å§‹å®éªŒ...")
    
    print("\nğŸƒ å¼€å§‹è®­ç»ƒ...\n")
    
    try:
        fsdp_finetune(config)
        
        print("\n" + "=" * 70)
        print("âœ… å®éªŒå®Œæˆï¼")
        print(f"ğŸ“¦ æ¨¡å‹å·²ä¿å­˜åˆ°: pruned_models/{model_name}-{target_sparsity}-finetuned.pt")
        print("=" * 70)
        print("\nğŸ“Š åç»­æ­¥éª¤ï¼š")
        print("   1. ä½¿ç”¨ Testing.ipynb è¯„ä¼°æ¨¡å‹æ€§èƒ½ (Perplexity)")
        print("   2. æµ‹è¯•ç”Ÿæˆè´¨é‡")
        print("   3. ä¸å…¶ä»–ç¨€ç–åº¦çš„æ¨¡å‹å¯¹æ¯”")
        print()
        print("ğŸ’¡ æç¤ºï¼š")
        print("   - å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼Œå°è¯•å¢åŠ  num_epochs æˆ–è°ƒæ•´ batch_size")
        print("   - å¯ä»¥å…ˆç”¨ 0.2 æˆ– 0.15 ç¨€ç–åº¦éªŒè¯æµç¨‹")
        print("   - æ›´å¤§çš„æ¨¡å‹ (opt-350m, opt-1.3b) å¯èƒ½å¯¹æé™å‹ç¼©æ›´é²æ£’")
        
    except Exception as e:
        print("\n" + "=" * 70)
        print("âŒ å®éªŒå¤±è´¥ï¼")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        print("=" * 70)
        raise


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æé™å‹ç¼©å®éªŒ")
    parser.add_argument(
        "--sparsity",
        type=float,
        default=0.1,
        help="ç›®æ ‡ç¨€ç–åº¦ (0.1=90%%å‹ç¼©, 0.05=95%%å‹ç¼©)"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="opt-125m",
        choices=["opt-125m", "opt-350m", "opt-1.3b"],
        help="æ¨¡å‹åç§°"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=1,
        help="æ‰¹å¤§å° (1=çœæ˜¾å­˜, 4=æ›´å¿«)"
    )
    
    args = parser.parse_args()
    
    extreme_compression_experiment(
        target_sparsity=args.sparsity,
        model_name=args.model,
        batch_size=args.batch_size
    )